{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green'> Introduction to python\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Python Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Python Interface\n",
    "\n",
    "In the Python script on the right, you can type Python code to solve the exercises. If you hit Run Code or Submit Answer, your python script (script.py) is executed and the output is shown in the IPython Shell. Submit Answer checks whether your submission is correct and gives you feedback.\n",
    "\n",
    "You can hit Run Code and Submit Answer as often as you want. If you're stuck, you can click Get Hint, and ultimately Get Solution.\n",
    "\n",
    "You can also use the IPython Shell interactively by simply typing commands and hitting Enter. When you work in the shell directly, your code will not be checked for correctness so it is a great way to experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "# Example, do not modify!\n",
    "print(5 / 8)\n",
    "\n",
    "# Print the sum of 7 and 10\n",
    "print(7+10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python as a calculator\n",
    "Python is perfectly suited to do basic calculations. Apart from addition, subtraction, multiplication and division, there is also support for more advanced operations such as:\n",
    "\n",
    "Exponentiation: ** . This operator raises the number to its left to the power of the number to its right. For example 4**2 will give 16.\n",
    "Modulo: %. This operator returns the remainder of the division of the number to the left by the number on its right. For example 18 % 7 equals 4.\n",
    "The code in the script gives some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0\n",
      "15\n",
      "5.0\n",
      "4\n",
      "16\n",
      "194.87171000000012\n"
     ]
    }
   ],
   "source": [
    "# Addition, subtraction\n",
    "print(5 + 5)\n",
    "print(5 - 5)\n",
    "\n",
    "# Multiplication, division, modulo, and exponentiation\n",
    "print(3 * 5)\n",
    "print(10 / 2)\n",
    "print(18 % 7)\n",
    "print(4 ** 2)\n",
    "\n",
    "# How much is your $100 worth after 7 years?\n",
    "print(100 * (1.1 ** 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Assignment\n",
    "In Python, a variable allows you to refer to a value with a name. To create a variable use =, like this example:\n",
    "\n",
    "x = 5\n",
    "\n",
    "You can now use the name of this variable, x, instead of the actual value, 5.\n",
    "\n",
    "Remember, = in Python means assignment, it doesn't test equality!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Create a variable savings\n",
    "savings = 100\n",
    "\n",
    "# Print out savings\n",
    "print(savings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations with variables\n",
    "Remember how you calculated the money you ended up with after 7 years of investing $100? You did something like this:\n",
    "\n",
    "100 * 1.1 ** 7\n",
    "\n",
    "Instead of calculating with the actual values, you can use variables instead. The savings variable you've created in the previous exercise represents the $100 you started with. It's up to you to create a new variable to represent 1.1 and then redo the calculations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194.87171000000012\n"
     ]
    }
   ],
   "source": [
    "# Create a variable savings\n",
    "savings = 100\n",
    "\n",
    "# Create a variable growth_multiplier\n",
    "growth_multiplier = 1.1\n",
    "\n",
    "# Calculate result\n",
    "result = savings * (growth_multiplier ** 7)\n",
    "\n",
    "# Print out result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 1\n",
      "a 2\n",
      "a 3\n",
      "b 1\n",
      "b 2\n",
      "b 3\n",
      "c 1\n",
      "c 2\n",
      "c 3\n"
     ]
    }
   ],
   "source": [
    "def print_alpha_nums(abc_list, num_list):\n",
    "     for char in abc_list:\n",
    "          for num in num_list:\n",
    "               print(char, num) \n",
    "print_alpha_nums(['a', 'b', 'c'], [1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other variable types\n",
    "In the previous exercise, you worked with two Python data types:\n",
    "\n",
    "- int, or integer: a number without a fractional part. savings, with the value 100, is an example of an integer.\n",
    "- float, or floating point: a number that has both an integer and fractional part, separated by a point. growth_multiplier, with the value 1.1, is an example of a float.\n",
    "\n",
    "Next to numerical data types, there are two other very common data types:\n",
    "\n",
    "- str, or string: a type to represent text. You can use single or double quotes to build a string.\n",
    "- bool, or boolean: a type to represent logical values. Can only be True or False (the capitalization is important!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable desc\n",
    "desc = \"compound interest\"\n",
    "\n",
    "# Create a variable profitable\n",
    "profitable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations with other types\n",
    "RUPyGOD mentioned that different types behave differently in Python.\n",
    "\n",
    "When you sum two strings, for example, you'll get different behavior than when you sum two integers or two booleans.\n",
    "\n",
    "In the script some variables with different types have already been created. It's up to you to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n",
      "compound interestcompound interest\n"
     ]
    }
   ],
   "source": [
    "savings = 100\n",
    "growth_multiplier = 1.1\n",
    "desc = \"compound interest\"\n",
    "\n",
    "# Assign product of savings and growth_multiplier to year1\n",
    "year1 = savings*growth_multiplier\n",
    "\n",
    "# Print the type of year1\n",
    "print(type(year1))\n",
    "\n",
    "# Assign sum of desc and desc to doubledesc\n",
    "doubledesc = desc + desc\n",
    "\n",
    "# Print out doubledesc\n",
    "print(doubledesc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type conversion\n",
    "Using the + operator to paste together two strings can be very useful in building custom messages.\n",
    "\n",
    "Suppose, for example, that you've calculated the return of your investment and want to summarize the results in a string. Assuming the integer savings and float result are defined, you can try something like this:\n",
    "\n",
    "print(\"I started with $\" + savings + \" and now have $\" + result + \". Awesome!\")\n",
    "\n",
    "This will not work, though, as you cannot simply sum strings and integers/floats.\n",
    "\n",
    "To fix the error, you'll need to explicitly convert the types of your variables. More specifically, you'll need str(), to convert a value into a string. str(savings), for example, will convert the integer savings to a string.\n",
    "\n",
    "Similar functions such as int(), float() and bool() will help you convert Python values into any type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I started with $100 and now have $194.87171000000012. Awesome!\n"
     ]
    }
   ],
   "source": [
    "# Definition of savings and result\n",
    "savings = 100\n",
    "result = 100 * 1.10 ** 7\n",
    "\n",
    "# Fix the printout\n",
    "print(\"I started with $\" + str(savings) + \" and now have $\" + str(result) + \". Awesome!\")\n",
    "\n",
    "# Definition of pi_string\n",
    "pi_string = \"3.1415926\"\n",
    "\n",
    "# Convert pi_string into float: pi_float\n",
    "pi_float = float(pi_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Python List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list\n",
    "As opposed to int, bool etc., a list is a **compound data type**; you can group values together:\n",
    "\n",
    "a = \"is\"\n",
    "\n",
    "b = \"nice\"\n",
    "\n",
    "my_list = [\"my\", \"list\", a, b]\n",
    "\n",
    "After measuring the height of your family, you decide to collect some information on the house you're living in. The areas of the different parts of your house are stored in separate variables for now, as shown in the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.25, 18.0, 20.0, 10.75, 9.5]\n"
     ]
    }
   ],
   "source": [
    "# area variables (in square meters)\n",
    "hall = 11.25\n",
    "kit = 18.0\n",
    "liv = 20.0\n",
    "bed = 10.75\n",
    "bath = 9.50\n",
    "\n",
    "# Create list areas\n",
    "areas = [hall,kit,liv,bed,bath]\n",
    "\n",
    "# Print areas\n",
    "print(areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list with different types\n",
    "A list can contain any Python type. Although it's not really common, a list can also contain a mix of Python types including strings, floats, booleans, etc.\n",
    "\n",
    "The printout of the previous exercise wasn't really satisfying. It's just a list of numbers representing the areas, but you can't tell which area corresponds to which part of your house.\n",
    "\n",
    "The code in the editor is the start of a solution. For some of the areas, the name of the corresponding room is already placed in front. Pay attention here! \"bathroom\" is a string, while bath is a variable that represents the float 9.50 you specified earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hallway', 11.25, 'kitchen', 18.0, 'living room', 20.0, 'bedroom', 10.75, 'bathroom', 9.5]\n"
     ]
    }
   ],
   "source": [
    "# area variables (in square meters)\n",
    "hall = 11.25\n",
    "kit = 18.0\n",
    "liv = 20.0\n",
    "bed = 10.75\n",
    "bath = 9.50\n",
    "\n",
    "# Adapt list areas\n",
    "areas = [\"hallway\",hall,'kitchen', kit, \"living room\", liv,\"bedroom\", bed, \"bathroom\", bath]\n",
    "\n",
    "# Print areas\n",
    "print(areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of lists\n",
    "As a data scientist, you'll often be dealing with a lot of data, and it will make sense to group some of this data.\n",
    "\n",
    "Instead of creating a flat list containing strings and floats, representing the names and areas of the rooms in your house, you can create a list of lists. The script in the editor can already give you an idea.\n",
    "\n",
    "Don't get confused here: \"hallway\" is a string, while hall is a variable that represents the float 11.25 you specified earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hallway', 11.25], ['kitchen', 18.0], ['living room', 20.0], ['bedroom', 10.75], ['bathroom', 9.5]]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# area variables (in square meters)\n",
    "hall = 11.25\n",
    "kit = 18.0\n",
    "liv = 20.0\n",
    "bed = 10.75\n",
    "bath = 9.50\n",
    "\n",
    "# house information as list of lists\n",
    "house = [[\"hallway\", hall],\n",
    "         [\"kitchen\", kit],\n",
    "         [\"living room\", liv],\n",
    "         [\"bedroom\", bed],\n",
    "         [\"bathroom\", bath]]\n",
    "\n",
    "# Print out house\n",
    "print(house)\n",
    "\n",
    "# Print out the type of house\n",
    "print(type(house))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset and conquer\n",
    "Subsetting Python lists is a piece of cake. Take the code sample below, which creates a list x and then selects \"b\" from it. Remember that this is the second element, so it has index 1. You can also use negative indexing.\n",
    "\n",
    "x = [\"a\", \"b\", \"c\", \"d\"]\n",
    "\n",
    "x[1]\n",
    "\n",
    "x[-3] # same result!\n",
    "\n",
    "Remember the areas list from before, containing both strings and floats? Its definition is already in the script. Can you add the correct code to do some Python subsetting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.25\n",
      "9.5\n",
      "20.0\n"
     ]
    }
   ],
   "source": [
    "# Create the areas list\n",
    "areas = [\"hallway\", 11.25, \"kitchen\", 18.0, \"living room\", 20.0, \"bedroom\", 10.75, \"bathroom\", 9.50]\n",
    "\n",
    "# Print out second element from areas\n",
    "print(areas[1])\n",
    "\n",
    "# Print out last element from areas\n",
    "print(areas[-1])\n",
    "\n",
    "# Print out the area of the living room\n",
    "print(areas[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset and calculate\n",
    "After you've extracted values from a list, you can use them to perform additional calculations. Take this example, where the second and fourth element of a list x are extracted. The strings that result are pasted together using the + operator:\n",
    "\n",
    "x = [\"a\", \"b\", \"c\", \"d\"]\n",
    "\n",
    "print(x[1] + x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.75\n"
     ]
    }
   ],
   "source": [
    "# Create the areas list\n",
    "areas = [\"hallway\", 11.25, \"kitchen\", 18.0, \"living room\", 20.0, \"bedroom\", 10.75, \"bathroom\", 9.50]\n",
    "\n",
    "# Sum of kitchen and bedroom area: eat_sleep_area\n",
    "eat_sleep_area = areas[3] + areas[-3]\n",
    "\n",
    "# Print the variable eat_sleep_area\n",
    "print(eat_sleep_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing and dicing\n",
    "Selecting single values from a list is just one part of the story. It's also possible to slice your list, which means selecting multiple elements from your list. Use the following syntax:\n",
    "\n",
    "my_list[start:end]\n",
    "\n",
    "The start index will be included, while the end index is not.\n",
    "\n",
    "The code sample below shows an example. A list with \"b\" and \"c\", corresponding to indexes 1 and 2, are selected from a list x:\n",
    "\n",
    "x = [\"a\", \"b\", \"c\", \"d\"]\n",
    "\n",
    "x[1:3]\n",
    "\n",
    "The elements with index 1 and 2 are included, while the element with index 3 is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hallway', 11.25, 'kitchen', 18.0, 'living room', 20.0]\n",
      "['bedroom', 10.75, 'bathroom', 9.5]\n"
     ]
    }
   ],
   "source": [
    "# Create the areas list\n",
    "areas = [\"hallway\", 11.25, \"kitchen\", 18.0, \"living room\", 20.0, \"bedroom\", 10.75, \"bathroom\", 9.50]\n",
    "\n",
    "# Use slicing to create downstairs\n",
    "downstairs = areas[0:6]\n",
    "\n",
    "# Use slicing to create upstairs\n",
    "upstairs = areas[6:10]\n",
    "\n",
    "# Print out downstairs and upstairs\n",
    "print(downstairs)\n",
    "print(upstairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing and dicing (2)\n",
    "In the video, Hugo first discussed the syntax where you specify both where to begin and end the slice of your list:\n",
    "\n",
    "my_list[begin:end]\n",
    "\n",
    "However, it's also possible not to specify these indexes. If you don't specify the begin index, Python figures out that you want to start your slice at the beginning of your list. If you don't specify the end index, the slice will go all the way to the last element of your list. To experiment with this, try the following commands in the IPython Shell:\n",
    "\n",
    "x = [\"a\", \"b\", \"c\", \"d\"]\n",
    "\n",
    "x[:2]\n",
    "\n",
    "x[2:]\n",
    "\n",
    "x[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the areas list\n",
    "areas = [\"hallway\", 11.25, \"kitchen\", 18.0, \"living room\", 20.0, \"bedroom\", 10.75, \"bathroom\", 9.50]\n",
    "\n",
    "# Alternative slicing to create downstairs\n",
    "downstairs = areas[:6]\n",
    "\n",
    "# Alternative slicing to create upstairs\n",
    "upstairs = areas[6:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace list elements\n",
    "Replacing list elements is pretty easy. Simply subset the list and assign new values to the subset. You can select single elements or you can change entire list slices at once.\n",
    "\n",
    "Use the IPython Shell to experiment with the commands below. Can you tell what's happening and why?\n",
    "\n",
    "x = [\"a\", \"b\", \"c\", \"d\"]\n",
    "\n",
    "x[1] = \"r\"\n",
    "\n",
    "x[2:] = [\"s\", \"t\"]\n",
    "\n",
    "For this and the following exercises, you'll continue working on the areas list that contains the names and areas of different rooms in a house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the areas list\n",
    "areas = [\"hallway\", 11.25, \"kitchen\", 18.0, \"living room\", 20.0, \"bedroom\", 10.75, \"bathroom\", 9.50]\n",
    "\n",
    "# Correct the bathroom area\n",
    "areas[-1] = 10.50\n",
    "\n",
    "# Change \"living room\" to \"chill zone\"\n",
    "areas[4] = \"chill zone\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend a list\n",
    "If you can change elements in a list, you sure want to be able to add elements to it, right? You can use the + operator:\n",
    "\n",
    "x = [\"a\", \"b\", \"c\", \"d\"]\n",
    "\n",
    "y = x + [\"e\", \"f\"]\n",
    "\n",
    "You just won the lottery, awesome! You decide to build a poolhouse and a garage. Can you add the information to the areas list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the areas list (updated version)\n",
    "areas = [\"hallway\", 11.25, \"kitchen\", 18.0, \"chill zone\", 20.0,\n",
    "         \"bedroom\", 10.75, \"bathroom\", 10.50]\n",
    "\n",
    "# Add poolhouse data to areas, new list is areas_1\n",
    "areas_1 = areas + [\"poolhouse\", 24.5]\n",
    "\n",
    "# Add garage data to areas_1, new list is areas_2\n",
    "areas_2 = areas_1 + [\"garage\", 15.45]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner workings of lists\n",
    "At the end of the video, Hugo explained how Python lists work behind the scenes. In this exercise you'll get some hands-on experience with this.\n",
    "\n",
    "The Python code in the script already creates a list with the name areas and a copy named areas_copy. Next, the first element in the areas_copy list is changed and the areas list is printed out. If you hit Run Code you'll see that, although you've changed areas_copy, the change also takes effect in the areas list. That's because areas and areas_copy point to the same list.\n",
    "\n",
    "If you want to prevent changes in areas_copy from also taking effect in areas, you'll have to do a more explicit copy of the areas list. You can do this with list() or by using [:]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.25, 18.0, 20.0, 10.75, 9.5]\n"
     ]
    }
   ],
   "source": [
    "# Create list areas\n",
    "areas = [11.25, 18.0, 20.0, 10.75, 9.50]\n",
    "\n",
    "# Create areas_copy\n",
    "areas_copy = list(areas)\n",
    "\n",
    "# Change areas_copy\n",
    "areas_copy[0] = 5.0\n",
    "\n",
    "# Print areas\n",
    "print(areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Familiar functions\n",
    "Out of the box, Python offers a bunch of built-in functions to make your life as a data scientist easier. You already know two such functions: print() and type(). You've also used the functions str(), int(), bool() and float() to switch between data types. These are built-in functions as well.\n",
    "\n",
    "Calling a function is easy. To get the type of 3.0 and store the output as a new variable, result, you can use the following:\n",
    "\n",
    "result = type(3.0)\n",
    "\n",
    "The general recipe for calling functions and saving the result to a variable is thus:\n",
    "\n",
    "output = function_name(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Create variables var1 and var2\n",
    "var1 = [1, 2, 3, 4]\n",
    "var2 = True\n",
    "\n",
    "# Print out type of var1\n",
    "print(type(var1))\n",
    "\n",
    "# Print out length of var1\n",
    "print(len(var1))\n",
    "\n",
    "# Convert var2 to an integer: out2\n",
    "out2 = int(var2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple arguments\n",
    "In the previous exercise, you identified optional arguments by viewing the documentation with help(). You'll now apply this to change the behavior of the sorted() function.\n",
    "\n",
    "Have a look at the documentation of sorted() by typing help(sorted) in the IPython Shell.\n",
    "\n",
    "You'll see that sorted() takes three arguments: iterable, key, and reverse.\n",
    "\n",
    "key=None means that if you don't specify the key argument, it will be None. reverse=False means that if you don't specify the reverse argument, it will be False, by default.\n",
    "\n",
    "In this exercise, you'll only have to specify iterable and reverse, not key. The first input you pass to sorted() will be matched to the iterable argument, but what about the second input? To tell Python you want to specify reverse without changing anything about key, you can use = to assign it a new value:\n",
    "\n",
    "sorted( _ _ _ _  , reverse=_ _ _ _)\n",
    "\n",
    "Two lists have been created for you. Can you paste them together and sort them in descending order?\n",
    "\n",
    "Note: For now, we can understand an iterable as being any collection of objects, e.g., a List."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20.0, 18.0, 11.25, 10.75, 9.5]\n"
     ]
    }
   ],
   "source": [
    "# Create lists first and second\n",
    "first = [11.25, 18.0, 20.0]\n",
    "second = [10.75, 9.50]\n",
    "\n",
    "# Paste together first and second: full\n",
    "full = first + second\n",
    "\n",
    "# Sort full in descending order: full_sorted\n",
    "full_sorted = sorted(full, reverse=True)\n",
    "\n",
    "# Print out full_sorted\n",
    "print(full_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='Green'> Manipulation data with pandas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='Red'> Transform Dataframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting a DataFrame\n",
    "When you get a new DataFrame to work with, the first thing you need to do is explore it and see what it contains. There are several useful methods and attributes for this.\n",
    "\n",
    "- head() returns the first few rows (the “head” of the DataFrame).\n",
    "\n",
    "- info() shows information on each of the columns, such as the data type and number of missing values.\n",
    "\n",
    "- shape returns the number of rows and columns of the DataFrame.\n",
    "\n",
    "- describe() calculates a few summary statistics for each column.\n",
    "\n",
    "homelessness is a DataFrame containing estimates of homelessness in each U.S. state in 2018. The individual column is the number of homeless individuals not part of a family with children. The family_members column is the number of homeless individuals part of a family with children. The state_pop column is the state's total population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0              region       state  individuals  family_members  \\\n",
      "0           0  East South Central     Alabama       2570.0           864.0   \n",
      "1           1             Pacific      Alaska       1434.0           582.0   \n",
      "2           2            Mountain     Arizona       7259.0          2606.0   \n",
      "3           3  West South Central    Arkansas       2280.0           432.0   \n",
      "4           4             Pacific  California     109008.0         20964.0   \n",
      "\n",
      "   state_pop  \n",
      "0    4887681  \n",
      "1     735139  \n",
      "2    7158024  \n",
      "3    3009733  \n",
      "4   39461588  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      51 non-null     int64  \n",
      " 1   region          51 non-null     object \n",
      " 2   state           51 non-null     object \n",
      " 3   individuals     51 non-null     float64\n",
      " 4   family_members  51 non-null     float64\n",
      " 5   state_pop       51 non-null     int64  \n",
      "dtypes: float64(2), int64(2), object(2)\n",
      "memory usage: 2.5+ KB\n",
      "None\n",
      "(51, 6)\n",
      "       Unnamed: 0    individuals  family_members     state_pop\n",
      "count   51.000000      51.000000       51.000000  5.100000e+01\n",
      "mean    25.000000    7225.784314     3504.882353  6.405637e+06\n",
      "std     14.866069   15991.025083     7805.411811  7.327258e+06\n",
      "min      0.000000     434.000000       75.000000  5.776010e+05\n",
      "25%     12.500000    1446.500000      592.000000  1.777414e+06\n",
      "50%     25.000000    3082.000000     1482.000000  4.461153e+06\n",
      "75%     37.500000    6781.500000     3196.000000  7.340946e+06\n",
      "max     50.000000  109008.000000    52070.000000  3.946159e+07\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "homelessness = pd.read_csv('dados/homelessness.csv')\n",
    "# Print the head of the homelessness data\n",
    "print(homelessness.head())\n",
    "\n",
    "# Print information about homelessness\n",
    "print(homelessness.info())\n",
    "\n",
    "# Print the shape of homelessness\n",
    "print(homelessness.shape)\n",
    "\n",
    "# Print a description of homelessness\n",
    "print(homelessness.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts of a DataFrame\n",
    "To better understand DataFrame objects, it's useful to know that they consist of three components, stored as attributes:\n",
    "\n",
    "- .values: A two-dimensional NumPy array of values.\n",
    "\n",
    "- .columns: An index of columns: the column names.\n",
    "\n",
    "- .index: An index for the rows: either row numbers or row names.\n",
    "\n",
    "You can usually think of indexes as a list of strings or numbers, though the pandas Index data type allows for more sophisticated options. (These will be covered later in the course.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 'East South Central' 'Alabama' 2570.0 864.0 4887681]\n",
      " [1 'Pacific' 'Alaska' 1434.0 582.0 735139]\n",
      " [2 'Mountain' 'Arizona' 7259.0 2606.0 7158024]\n",
      " [3 'West South Central' 'Arkansas' 2280.0 432.0 3009733]\n",
      " [4 'Pacific' 'California' 109008.0 20964.0 39461588]\n",
      " [5 'Mountain' 'Colorado' 7607.0 3250.0 5691287]\n",
      " [6 'New England' 'Connecticut' 2280.0 1696.0 3571520]\n",
      " [7 'South Atlantic' 'Delaware' 708.0 374.0 965479]\n",
      " [8 'South Atlantic' 'District of Columbia' 3770.0 3134.0 701547]\n",
      " [9 'South Atlantic' 'Florida' 21443.0 9587.0 21244317]\n",
      " [10 'South Atlantic' 'Georgia' 6943.0 2556.0 10511131]\n",
      " [11 'Pacific' 'Hawaii' 4131.0 2399.0 1420593]\n",
      " [12 'Mountain' 'Idaho' 1297.0 715.0 1750536]\n",
      " [13 'East North Central' 'Illinois' 6752.0 3891.0 12723071]\n",
      " [14 'East North Central' 'Indiana' 3776.0 1482.0 6695497]\n",
      " [15 'West North Central' 'Iowa' 1711.0 1038.0 3148618]\n",
      " [16 'West North Central' 'Kansas' 1443.0 773.0 2911359]\n",
      " [17 'East South Central' 'Kentucky' 2735.0 953.0 4461153]\n",
      " [18 'West South Central' 'Louisiana' 2540.0 519.0 4659690]\n",
      " [19 'New England' 'Maine' 1450.0 1066.0 1339057]\n",
      " [20 'South Atlantic' 'Maryland' 4914.0 2230.0 6035802]\n",
      " [21 'New England' 'Massachusetts' 6811.0 13257.0 6882635]\n",
      " [22 'East North Central' 'Michigan' 5209.0 3142.0 9984072]\n",
      " [23 'West North Central' 'Minnesota' 3993.0 3250.0 5606249]\n",
      " [24 'East South Central' 'Mississippi' 1024.0 328.0 2981020]\n",
      " [25 'West North Central' 'Missouri' 3776.0 2107.0 6121623]\n",
      " [26 'Mountain' 'Montana' 983.0 422.0 1060665]\n",
      " [27 'West North Central' 'Nebraska' 1745.0 676.0 1925614]\n",
      " [28 'Mountain' 'Nevada' 7058.0 486.0 3027341]\n",
      " [29 'New England' 'New Hampshire' 835.0 615.0 1353465]\n",
      " [30 'Mid-Atlantic' 'New Jersey' 6048.0 3350.0 8886025]\n",
      " [31 'Mountain' 'New Mexico' 1949.0 602.0 2092741]\n",
      " [32 'Mid-Atlantic' 'New York' 39827.0 52070.0 19530351]\n",
      " [33 'South Atlantic' 'North Carolina' 6451.0 2817.0 10381615]\n",
      " [34 'West North Central' 'North Dakota' 467.0 75.0 758080]\n",
      " [35 'East North Central' 'Ohio' 6929.0 3320.0 11676341]\n",
      " [36 'West South Central' 'Oklahoma' 2823.0 1048.0 3940235]\n",
      " [37 'Pacific' 'Oregon' 11139.0 3337.0 4181886]\n",
      " [38 'Mid-Atlantic' 'Pennsylvania' 8163.0 5349.0 12800922]\n",
      " [39 'New England' 'Rhode Island' 747.0 354.0 1058287]\n",
      " [40 'South Atlantic' 'South Carolina' 3082.0 851.0 5084156]\n",
      " [41 'West North Central' 'South Dakota' 836.0 323.0 878698]\n",
      " [42 'East South Central' 'Tennessee' 6139.0 1744.0 6771631]\n",
      " [43 'West South Central' 'Texas' 19199.0 6111.0 28628666]\n",
      " [44 'Mountain' 'Utah' 1904.0 972.0 3153550]\n",
      " [45 'New England' 'Vermont' 780.0 511.0 624358]\n",
      " [46 'South Atlantic' 'Virginia' 3928.0 2047.0 8501286]\n",
      " [47 'Pacific' 'Washington' 16424.0 5880.0 7523869]\n",
      " [48 'South Atlantic' 'West Virginia' 1021.0 222.0 1804291]\n",
      " [49 'East North Central' 'Wisconsin' 2740.0 2167.0 5807406]\n",
      " [50 'Mountain' 'Wyoming' 434.0 205.0 577601]]\n",
      "Index(['Unnamed: 0', 'region', 'state', 'individuals', 'family_members',\n",
      "       'state_pop'],\n",
      "      dtype='object')\n",
      "RangeIndex(start=0, stop=51, step=1)\n"
     ]
    }
   ],
   "source": [
    "# Import pandas using the alias pd\n",
    "import pandas as pd\n",
    "\n",
    "# Print the values of homelessness\n",
    "print(homelessness.values)\n",
    "\n",
    "# Print the column index of homelessness\n",
    "print(homelessness.columns)\n",
    "\n",
    "# Print the row index of homelessness\n",
    "print(homelessness.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting rows\n",
    "Finding interesting bits of data in a DataFrame is often easier if you change the order of the rows. You can sort the rows by passing a column name to .sort_values().\n",
    "\n",
    "In cases where rows have the same value (this is common if you sort on a categorical variable), you may wish to break the ties by sorting on another column. You can sort on multiple columns in this way by passing a list of column names.\n",
    "\n",
    "Sort on |\tSyntax\n",
    "\n",
    "one column | df.sort_values(\"breed\")\n",
    "\n",
    "multiple columns | df.sort_values([\"breed\", \"weight_kg\"])\n",
    "\n",
    "By combining .sort_values() with .head(), you can answer questions in the form, \"What are the top cases where…?\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0              region         state  individuals  family_members  \\\n",
      "50          50            Mountain       Wyoming        434.0           205.0   \n",
      "34          34  West North Central  North Dakota        467.0            75.0   \n",
      "7            7      South Atlantic      Delaware        708.0           374.0   \n",
      "39          39         New England  Rhode Island        747.0           354.0   \n",
      "45          45         New England       Vermont        780.0           511.0   \n",
      "\n",
      "    state_pop  \n",
      "50     577601  \n",
      "34     758080  \n",
      "7      965479  \n",
      "39    1058287  \n",
      "45     624358  \n"
     ]
    }
   ],
   "source": [
    "# Sort homelessness by individuals\n",
    "homelessness_ind = homelessness.sort_values(['individuals'])\n",
    "\n",
    "# Print the top few rows\n",
    "print(homelessness_ind.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0              region          state  individuals  \\\n",
      "32          32        Mid-Atlantic       New York      39827.0   \n",
      "4            4             Pacific     California     109008.0   \n",
      "21          21         New England  Massachusetts       6811.0   \n",
      "9            9      South Atlantic        Florida      21443.0   \n",
      "43          43  West South Central          Texas      19199.0   \n",
      "\n",
      "    family_members  state_pop  \n",
      "32         52070.0   19530351  \n",
      "4          20964.0   39461588  \n",
      "21         13257.0    6882635  \n",
      "9           9587.0   21244317  \n",
      "43          6111.0   28628666  \n"
     ]
    }
   ],
   "source": [
    "# Sort homelessness by descending family members\n",
    "homelessness_fam = homelessness.sort_values(['family_members'],ascending = False)\n",
    "\n",
    "# Print the top few rows\n",
    "print(homelessness_fam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0              region      state  individuals  family_members  \\\n",
      "13          13  East North Central   Illinois       6752.0          3891.0   \n",
      "35          35  East North Central       Ohio       6929.0          3320.0   \n",
      "22          22  East North Central   Michigan       5209.0          3142.0   \n",
      "49          49  East North Central  Wisconsin       2740.0          2167.0   \n",
      "14          14  East North Central    Indiana       3776.0          1482.0   \n",
      "\n",
      "    state_pop  \n",
      "13   12723071  \n",
      "35   11676341  \n",
      "22    9984072  \n",
      "49    5807406  \n",
      "14    6695497  \n"
     ]
    }
   ],
   "source": [
    "# Sort homelessness by region, then descending family members\n",
    "homelessness_reg_fam = homelessness.sort_values(['region','family_members'],ascending = [True,False])\n",
    "\n",
    "# Print the top few rows\n",
    "print(homelessness_reg_fam.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting columns\n",
    "\n",
    "When working with data, you may not need all of the variables in your dataset. Square brackets ([]) can be used to select only the columns that matter to you in an order that makes sense to you. To select only \"col_a\" of the DataFrame df, use\n",
    "\n",
    "df[\"col_a\"]\n",
    "\n",
    "To select \"col_a\" and \"col_b\" of df, use\n",
    "\n",
    "df[[\"col_a\", \"col_b\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2570.0\n",
      "1      1434.0\n",
      "2      7259.0\n",
      "3      2280.0\n",
      "4    109008.0\n",
      "Name: individuals, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Select the individuals column\n",
    "individuals = homelessness['individuals']\n",
    "\n",
    "# Print the head of the result\n",
    "print(individuals.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        state  family_members\n",
      "0     Alabama           864.0\n",
      "1      Alaska           582.0\n",
      "2     Arizona          2606.0\n",
      "3    Arkansas           432.0\n",
      "4  California         20964.0\n"
     ]
    }
   ],
   "source": [
    "# Select the state and family_members columns\n",
    "state_fam = homelessness[['state','family_members']]\n",
    "\n",
    "# Print the head of the result\n",
    "print(state_fam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   individuals       state\n",
      "0       2570.0     Alabama\n",
      "1       1434.0      Alaska\n",
      "2       7259.0     Arizona\n",
      "3       2280.0    Arkansas\n",
      "4     109008.0  California\n"
     ]
    }
   ],
   "source": [
    "# Select only the individuals and state columns, in that order\n",
    "ind_state = homelessness[['individuals','state']]\n",
    "\n",
    "# Print the head of the result\n",
    "print(ind_state.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting rows\n",
    "A large part of data science is about finding which bits of your dataset are interesting. One of the simplest techniques for this is to find a subset of rows that match some criteria. This is sometimes known as filtering rows or selecting rows.\n",
    "\n",
    "There are many ways to subset a DataFrame, perhaps the most common is to use relational operators to return True or False for each row, then pass that inside square brackets.\n",
    "\n",
    "dogs[dogs[\"height_cm\"] > 60]\n",
    "\n",
    "dogs[dogs[\"color\"] == \"tan\"]\n",
    "\n",
    "You can filter for multiple conditions at once by using the \"bitwise and\" operator, &.\n",
    "\n",
    "dogs[(dogs[\"height_cm\"] > 60) & (dogs[\"color\"] == \"tan\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0              region       state  individuals  family_members  \\\n",
      "4            4             Pacific  California     109008.0         20964.0   \n",
      "9            9      South Atlantic     Florida      21443.0          9587.0   \n",
      "32          32        Mid-Atlantic    New York      39827.0         52070.0   \n",
      "37          37             Pacific      Oregon      11139.0          3337.0   \n",
      "43          43  West South Central       Texas      19199.0          6111.0   \n",
      "47          47             Pacific  Washington      16424.0          5880.0   \n",
      "\n",
      "    state_pop  \n",
      "4    39461588  \n",
      "9    21244317  \n",
      "32   19530351  \n",
      "37    4181886  \n",
      "43   28628666  \n",
      "47    7523869  \n"
     ]
    }
   ],
   "source": [
    "# Filter for rows where individuals is greater than 10000\n",
    "ind_gt_10k = homelessness[homelessness['individuals']>10000]\n",
    "\n",
    "# See the result\n",
    "print(ind_gt_10k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0    region       state  individuals  family_members  state_pop\n",
      "2            2  Mountain     Arizona       7259.0          2606.0    7158024\n",
      "5            5  Mountain    Colorado       7607.0          3250.0    5691287\n",
      "12          12  Mountain       Idaho       1297.0           715.0    1750536\n",
      "26          26  Mountain     Montana        983.0           422.0    1060665\n",
      "28          28  Mountain      Nevada       7058.0           486.0    3027341\n",
      "31          31  Mountain  New Mexico       1949.0           602.0    2092741\n",
      "44          44  Mountain        Utah       1904.0           972.0    3153550\n",
      "50          50  Mountain     Wyoming        434.0           205.0     577601\n"
     ]
    }
   ],
   "source": [
    "# Filter for rows where region is Mountain\n",
    "mountain_reg = homelessness[homelessness['region']=='Mountain']\n",
    "\n",
    "# See the result\n",
    "print(mountain_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0   region   state  individuals  family_members  state_pop\n",
      "1           1  Pacific  Alaska       1434.0           582.0     735139\n"
     ]
    }
   ],
   "source": [
    "# Filter for rows where family_members is less than 1000 \n",
    "# and region is Pacific\n",
    "fam_lt_1k_pac = homelessness[(homelessness['family_members']<1000) & (homelessness['region']=='Pacific')]\n",
    "\n",
    "# See the result\n",
    "print(fam_lt_1k_pac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting rows by categorical variables\n",
    "Subsetting data based on a categorical variable often involves using the \"or\" operator (|) to select rows from multiple categories. This can get tedious when you want all states in one of three different regions, for example. Instead, use the .isin() method, which will allow you to tackle this problem by writing one condition instead of three separate ones.\n",
    "\n",
    "colors = [\"brown\", \"black\", \"tan\"]\n",
    "\n",
    "condition = dogs[\"color\"].isin(colors)\n",
    "\n",
    "dogs[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0          region                 state  individuals  \\\n",
      "7            7  South Atlantic              Delaware        708.0   \n",
      "8            8  South Atlantic  District of Columbia       3770.0   \n",
      "9            9  South Atlantic               Florida      21443.0   \n",
      "10          10  South Atlantic               Georgia       6943.0   \n",
      "20          20  South Atlantic              Maryland       4914.0   \n",
      "30          30    Mid-Atlantic            New Jersey       6048.0   \n",
      "32          32    Mid-Atlantic              New York      39827.0   \n",
      "33          33  South Atlantic        North Carolina       6451.0   \n",
      "38          38    Mid-Atlantic          Pennsylvania       8163.0   \n",
      "40          40  South Atlantic        South Carolina       3082.0   \n",
      "46          46  South Atlantic              Virginia       3928.0   \n",
      "48          48  South Atlantic         West Virginia       1021.0   \n",
      "\n",
      "    family_members  state_pop  \n",
      "7            374.0     965479  \n",
      "8           3134.0     701547  \n",
      "9           9587.0   21244317  \n",
      "10          2556.0   10511131  \n",
      "20          2230.0    6035802  \n",
      "30          3350.0    8886025  \n",
      "32         52070.0   19530351  \n",
      "33          2817.0   10381615  \n",
      "38          5349.0   12800922  \n",
      "40           851.0    5084156  \n",
      "46          2047.0    8501286  \n",
      "48           222.0    1804291  \n"
     ]
    }
   ],
   "source": [
    "# Subset for rows in South Atlantic or Mid-Atlantic regions\n",
    "south_mid_atlantic = homelessness[homelessness['region'].isin(['South Atlantic','Mid-Atlantic'])]\n",
    "\n",
    "# See the result\n",
    "print(south_mid_atlantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0    region       state  individuals  family_members  state_pop\n",
      "2            2  Mountain     Arizona       7259.0          2606.0    7158024\n",
      "4            4   Pacific  California     109008.0         20964.0   39461588\n",
      "28          28  Mountain      Nevada       7058.0           486.0    3027341\n",
      "44          44  Mountain        Utah       1904.0           972.0    3153550\n"
     ]
    }
   ],
   "source": [
    "# The Mojave Desert states\n",
    "canu = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n",
    "\n",
    "# Filter for rows in the Mojave Desert states\n",
    "mojave_homelessness = homelessness[homelessness['state'].isin(canu)]\n",
    "\n",
    "# See the result\n",
    "print(mojave_homelessness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new columns\n",
    "You aren't stuck with just the data you are given. Instead, you can add new columns to a DataFrame. This has many names, such as transforming, mutating, and feature engineering.\n",
    "\n",
    "You can create new columns from scratch, but it is also common to derive them from other columns, for example, by adding columns together or by changing their units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0              region                 state  individuals  \\\n",
      "0            0  East South Central               Alabama       2570.0   \n",
      "1            1             Pacific                Alaska       1434.0   \n",
      "2            2            Mountain               Arizona       7259.0   \n",
      "3            3  West South Central              Arkansas       2280.0   \n",
      "4            4             Pacific            California     109008.0   \n",
      "5            5            Mountain              Colorado       7607.0   \n",
      "6            6         New England           Connecticut       2280.0   \n",
      "7            7      South Atlantic              Delaware        708.0   \n",
      "8            8      South Atlantic  District of Columbia       3770.0   \n",
      "9            9      South Atlantic               Florida      21443.0   \n",
      "10          10      South Atlantic               Georgia       6943.0   \n",
      "11          11             Pacific                Hawaii       4131.0   \n",
      "12          12            Mountain                 Idaho       1297.0   \n",
      "13          13  East North Central              Illinois       6752.0   \n",
      "14          14  East North Central               Indiana       3776.0   \n",
      "15          15  West North Central                  Iowa       1711.0   \n",
      "16          16  West North Central                Kansas       1443.0   \n",
      "17          17  East South Central              Kentucky       2735.0   \n",
      "18          18  West South Central             Louisiana       2540.0   \n",
      "19          19         New England                 Maine       1450.0   \n",
      "20          20      South Atlantic              Maryland       4914.0   \n",
      "21          21         New England         Massachusetts       6811.0   \n",
      "22          22  East North Central              Michigan       5209.0   \n",
      "23          23  West North Central             Minnesota       3993.0   \n",
      "24          24  East South Central           Mississippi       1024.0   \n",
      "25          25  West North Central              Missouri       3776.0   \n",
      "26          26            Mountain               Montana        983.0   \n",
      "27          27  West North Central              Nebraska       1745.0   \n",
      "28          28            Mountain                Nevada       7058.0   \n",
      "29          29         New England         New Hampshire        835.0   \n",
      "30          30        Mid-Atlantic            New Jersey       6048.0   \n",
      "31          31            Mountain            New Mexico       1949.0   \n",
      "32          32        Mid-Atlantic              New York      39827.0   \n",
      "33          33      South Atlantic        North Carolina       6451.0   \n",
      "34          34  West North Central          North Dakota        467.0   \n",
      "35          35  East North Central                  Ohio       6929.0   \n",
      "36          36  West South Central              Oklahoma       2823.0   \n",
      "37          37             Pacific                Oregon      11139.0   \n",
      "38          38        Mid-Atlantic          Pennsylvania       8163.0   \n",
      "39          39         New England          Rhode Island        747.0   \n",
      "40          40      South Atlantic        South Carolina       3082.0   \n",
      "41          41  West North Central          South Dakota        836.0   \n",
      "42          42  East South Central             Tennessee       6139.0   \n",
      "43          43  West South Central                 Texas      19199.0   \n",
      "44          44            Mountain                  Utah       1904.0   \n",
      "45          45         New England               Vermont        780.0   \n",
      "46          46      South Atlantic              Virginia       3928.0   \n",
      "47          47             Pacific            Washington      16424.0   \n",
      "48          48      South Atlantic         West Virginia       1021.0   \n",
      "49          49  East North Central             Wisconsin       2740.0   \n",
      "50          50            Mountain               Wyoming        434.0   \n",
      "\n",
      "    family_members  state_pop     total  p_individuals  \n",
      "0            864.0    4887681    3434.0       0.748398  \n",
      "1            582.0     735139    2016.0       0.711310  \n",
      "2           2606.0    7158024    9865.0       0.735834  \n",
      "3            432.0    3009733    2712.0       0.840708  \n",
      "4          20964.0   39461588  129972.0       0.838704  \n",
      "5           3250.0    5691287   10857.0       0.700654  \n",
      "6           1696.0    3571520    3976.0       0.573441  \n",
      "7            374.0     965479    1082.0       0.654344  \n",
      "8           3134.0     701547    6904.0       0.546060  \n",
      "9           9587.0   21244317   31030.0       0.691041  \n",
      "10          2556.0   10511131    9499.0       0.730919  \n",
      "11          2399.0    1420593    6530.0       0.632619  \n",
      "12           715.0    1750536    2012.0       0.644632  \n",
      "13          3891.0   12723071   10643.0       0.634408  \n",
      "14          1482.0    6695497    5258.0       0.718144  \n",
      "15          1038.0    3148618    2749.0       0.622408  \n",
      "16           773.0    2911359    2216.0       0.651173  \n",
      "17           953.0    4461153    3688.0       0.741594  \n",
      "18           519.0    4659690    3059.0       0.830337  \n",
      "19          1066.0    1339057    2516.0       0.576312  \n",
      "20          2230.0    6035802    7144.0       0.687850  \n",
      "21         13257.0    6882635   20068.0       0.339396  \n",
      "22          3142.0    9984072    8351.0       0.623758  \n",
      "23          3250.0    5606249    7243.0       0.551291  \n",
      "24           328.0    2981020    1352.0       0.757396  \n",
      "25          2107.0    6121623    5883.0       0.641849  \n",
      "26           422.0    1060665    1405.0       0.699644  \n",
      "27           676.0    1925614    2421.0       0.720777  \n",
      "28           486.0    3027341    7544.0       0.935578  \n",
      "29           615.0    1353465    1450.0       0.575862  \n",
      "30          3350.0    8886025    9398.0       0.643541  \n",
      "31           602.0    2092741    2551.0       0.764014  \n",
      "32         52070.0   19530351   91897.0       0.433387  \n",
      "33          2817.0   10381615    9268.0       0.696051  \n",
      "34            75.0     758080     542.0       0.861624  \n",
      "35          3320.0   11676341   10249.0       0.676066  \n",
      "36          1048.0    3940235    3871.0       0.729269  \n",
      "37          3337.0    4181886   14476.0       0.769481  \n",
      "38          5349.0   12800922   13512.0       0.604130  \n",
      "39           354.0    1058287    1101.0       0.678474  \n",
      "40           851.0    5084156    3933.0       0.783626  \n",
      "41           323.0     878698    1159.0       0.721311  \n",
      "42          1744.0    6771631    7883.0       0.778764  \n",
      "43          6111.0   28628666   25310.0       0.758554  \n",
      "44           972.0    3153550    2876.0       0.662031  \n",
      "45           511.0     624358    1291.0       0.604183  \n",
      "46          2047.0    8501286    5975.0       0.657406  \n",
      "47          5880.0    7523869   22304.0       0.736370  \n",
      "48           222.0    1804291    1243.0       0.821400  \n",
      "49          2167.0    5807406    4907.0       0.558386  \n",
      "50           205.0     577601     639.0       0.679186  \n"
     ]
    }
   ],
   "source": [
    "# Add total col as sum of individuals and family_members\n",
    "homelessness['total']=homelessness['individuals']+homelessness['family_members']\n",
    "\n",
    "# Add p_individuals col as proportion of total that are individuals\n",
    "homelessness['p_individuals'] = homelessness['individuals']/homelessness['total']\n",
    "\n",
    "# See the result\n",
    "print(homelessness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combo-attack!\n",
    "You've seen the four most common types of data manipulation: sorting rows, subsetting columns, subsetting rows, and adding new columns. In a real-life data analysis, you can mix and match these four manipulations to answer a multitude of questions.\n",
    "\n",
    "In this exercise, you'll answer the question, \"Which state has the highest number of homeless individuals per 10,000 people in the state?\" Combine your new pandas skills to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   state  indiv_per_10k\n",
      "8   District of Columbia      53.738381\n",
      "11                Hawaii      29.079406\n",
      "4             California      27.623825\n",
      "37                Oregon      26.636307\n",
      "28                Nevada      23.314189\n",
      "47            Washington      21.829195\n",
      "32              New York      20.392363\n"
     ]
    }
   ],
   "source": [
    "# Create indiv_per_10k col as homeless individuals per 10k state pop\n",
    "homelessness[\"indiv_per_10k\"] = 10000 * homelessness[\"individuals\"] / homelessness[\"state_pop\"] \n",
    "\n",
    "# Subset rows for indiv_per_10k greater than 20\n",
    "high_homelessness = homelessness[homelessness[\"indiv_per_10k\"] > 20]\n",
    "\n",
    "# Sort high_homelessness by descending indiv_per_10k\n",
    "high_homelessness_srt = high_homelessness.sort_values(\"indiv_per_10k\", ascending=False)\n",
    "\n",
    "# From high_homelessness_srt, select the state and indiv_per_10k cols\n",
    "result = high_homelessness_srt[[\"state\", \"indiv_per_10k\"]]\n",
    "\n",
    "# See the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='Red'> Aggregating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('dados/sales_subset.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and median\n",
    "Summary statistics are exactly what they sound like - they summarize many numbers in one statistic. For example, mean, median, minimum, maximum, and standard deviation are summary statistics. Calculating summary statistics allows you to get a better sense of your data, even if there's a lot of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  store type  department        date  weekly_sales  is_holiday  \\\n",
      "0           0      1    A           1  2010-02-05      24924.50       False   \n",
      "1           1      1    A           1  2010-03-05      21827.90       False   \n",
      "2           2      1    A           1  2010-04-02      57258.43       False   \n",
      "3           3      1    A           1  2010-05-07      17413.94       False   \n",
      "4           4      1    A           1  2010-06-04      17558.09       False   \n",
      "\n",
      "   temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0       5.727778              0.679451         8.106  \n",
      "1       8.055556              0.693452         8.106  \n",
      "2      16.816667              0.718284         7.808  \n",
      "3      22.527778              0.748928         7.808  \n",
      "4      27.050000              0.714586         7.808  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10774 entries, 0 to 10773\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Unnamed: 0            10774 non-null  int64  \n",
      " 1   store                 10774 non-null  int64  \n",
      " 2   type                  10774 non-null  object \n",
      " 3   department            10774 non-null  int64  \n",
      " 4   date                  10774 non-null  object \n",
      " 5   weekly_sales          10774 non-null  float64\n",
      " 6   is_holiday            10774 non-null  bool   \n",
      " 7   temperature_c         10774 non-null  float64\n",
      " 8   fuel_price_usd_per_l  10774 non-null  float64\n",
      " 9   unemployment          10774 non-null  float64\n",
      "dtypes: bool(1), float64(4), int64(3), object(2)\n",
      "memory usage: 768.2+ KB\n",
      "None\n",
      "23843.950148505668\n",
      "12049.064999999999\n"
     ]
    }
   ],
   "source": [
    "# Print the head of the sales DataFrame\n",
    "print(sales.head())\n",
    "\n",
    "# Print the info about the sales DataFrame\n",
    "print(sales.info())\n",
    "\n",
    "# Print the mean of weekly_sales\n",
    "print(sales[\"weekly_sales\"].mean())\n",
    "\n",
    "# Print the median of weekly_sales\n",
    "print(sales[\"weekly_sales\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing dates\n",
    "Summary statistics can also be calculated on date columns that have values with the data type datetime64. Some summary statistics — like mean — don't make a ton of sense on dates, but others are super helpful, for example, minimum and maximum, which allow you to see what time range your data covers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-10-26\n",
      "2010-02-05\n"
     ]
    }
   ],
   "source": [
    "# Print the maximum of the date column\n",
    "print(sales['date'].max())\n",
    "\n",
    "# Print the minimum of the date column\n",
    "print(sales['date'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficient summaries\n",
    "While pandas and NumPy have tons of functions, sometimes, you may need a different function to summarize your data.\n",
    "\n",
    "The .agg() method allows you to apply your own custom functions to a DataFrame, as well as apply functions to more than one column of a DataFrame at once, making your aggregations super-efficient. For example,\n",
    "\n",
    "df['column'].agg(function)\n",
    "\n",
    "In the custom function for this exercise, \"IQR\" is short for inter-quartile range, which is the 75th percentile minus the 25th percentile. It's an alternative to standard deviation that is helpful if your data contains outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.583333333333336\n"
     ]
    }
   ],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "    \n",
    "# Print IQR of the temperature_c column\n",
    "print(sales['temperature_c'].agg(iqr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature_c           16.583333\n",
      "fuel_price_usd_per_l     0.073176\n",
      "unemployment             0.565000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(sales[[\"temperature_c\", 'fuel_price_usd_per_l','unemployment']].agg(iqr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        temperature_c  fuel_price_usd_per_l  unemployment\n",
      "iqr         16.583333              0.073176         0.565\n",
      "median      16.966667              0.743381         8.099\n"
     ]
    }
   ],
   "source": [
    "# Import NumPy and create custom IQR function\n",
    "import numpy as np\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Update to print IQR and median of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr,np.median]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative statistics\n",
    "Cumulative statistics can also be helpful in tracking summary statistics over time. In this exercise, you'll calculate the cumulative sum and cumulative max of a department's weekly sales, which will allow you to identify what the total sales were so far as well as what the highest weekly sales were so far.\n",
    "\n",
    "A DataFrame called sales_1_1 has been created for you, which contains the sales data for department 1 of store 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  weekly_sales  cum_weekly_sales  cum_max_sales\n",
      "0   2010-02-05      24924.50          24924.50       24924.50\n",
      "1   2010-03-05      21827.90          46752.40       24924.50\n",
      "2   2010-04-02      57258.43         104010.83       57258.43\n",
      "3   2010-05-07      17413.94         121424.77       57258.43\n",
      "4   2010-06-04      17558.09         138982.86       57258.43\n",
      "5   2010-07-02      16333.14         155316.00       57258.43\n",
      "6   2010-08-06      17508.41         172824.41       57258.43\n",
      "7   2010-09-03      16241.78         189066.19       57258.43\n",
      "8   2010-10-01      20094.19         209160.38       57258.43\n",
      "9   2010-11-05      34238.88         243399.26       57258.43\n",
      "10  2010-12-03      22517.56         265916.82       57258.43\n",
      "11  2011-01-07      15984.24         281901.06       57258.43\n"
     ]
    }
   ],
   "source": [
    "sales_1_1 = sales.query('store == 1 and department ==1')\n",
    "# Sort sales_1_1 by date\n",
    "sales_1_1 = sales_1_1.sort_values(\"date\")\n",
    "\n",
    "# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col\n",
    "sales_1_1[\"cum_weekly_sales\"] = sales_1_1[\"weekly_sales\"].cumsum()\n",
    "\n",
    "# Get the cumulative max of weekly_sales, add as cum_max_sales col\n",
    "sales_1_1[\"cum_max_sales\"] = sales_1_1[\"weekly_sales\"].cummax()\n",
    "\n",
    "# See the columns you calculated\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping duplicates\n",
    "Removing duplicates is an essential skill to get accurate counts because often, you don't want to count the same thing multiple times. In this exercise, you'll create some new DataFrames using unique values from sales.\n",
    "\n",
    "sales is available and pandas is imported as pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  store type  department        date  weekly_sales  \\\n",
      "0              0      1    A           1  2010-02-05      24924.50   \n",
      "901          901      2    A           1  2010-02-05      35034.06   \n",
      "1798        1798      4    A           1  2010-02-05      38724.42   \n",
      "2699        2699      6    A           1  2010-02-05      25619.00   \n",
      "3593        3593     10    B           1  2010-02-05      40212.84   \n",
      "\n",
      "      is_holiday  temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0          False       5.727778              0.679451         8.106  \n",
      "901        False       4.550000              0.679451         8.324  \n",
      "1798       False       6.533333              0.686319         8.623  \n",
      "2699       False       4.683333              0.679451         7.259  \n",
      "3593       False      12.411111              0.782478         9.765  \n",
      "    Unnamed: 0  store type  department        date  weekly_sales  is_holiday  \\\n",
      "0            0      1    A           1  2010-02-05      24924.50       False   \n",
      "12          12      1    A           2  2010-02-05      50605.27       False   \n",
      "24          24      1    A           3  2010-02-05      13740.12       False   \n",
      "36          36      1    A           4  2010-02-05      39954.04       False   \n",
      "48          48      1    A           5  2010-02-05      32229.38       False   \n",
      "\n",
      "    temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0        5.727778              0.679451         8.106  \n",
      "12       5.727778              0.679451         8.106  \n",
      "24       5.727778              0.679451         8.106  \n",
      "36       5.727778              0.679451         8.106  \n",
      "48       5.727778              0.679451         8.106  \n",
      "498     2010-09-10\n",
      "691     2011-11-25\n",
      "2315    2010-02-12\n",
      "6735    2012-09-07\n",
      "6810    2010-12-31\n",
      "6815    2012-02-10\n",
      "6820    2011-09-09\n",
      "Name: date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate store/type combinations\n",
    "store_types = sales.drop_duplicates(subset=[\"store\", \"type\"])\n",
    "print(store_types.head())\n",
    "\n",
    "# Drop duplicate store/department combinations\n",
    "store_depts = sales.drop_duplicates(subset=[\"store\", \"department\"])\n",
    "print(store_depts.head())\n",
    "\n",
    "# Subset the rows where is_holiday is True and drop duplicate dates\n",
    "holiday_dates = sales[sales[\"is_holiday\"]].drop_duplicates(subset=\"date\")\n",
    "\n",
    "# Print date col of holiday_dates\n",
    "print(holiday_dates[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting categorical variables\n",
    "Counting is a great way to get an overview of your data and to spot curiosities that you might not notice otherwise. In this exercise, you'll count the number of each type of store and the number of each department number using the DataFrames you created in the previous exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    11\n",
      "B     1\n",
      "Name: type, dtype: int64\n",
      "A    0.916667\n",
      "B    0.083333\n",
      "Name: type, dtype: float64\n",
      "1     12\n",
      "55    12\n",
      "72    12\n",
      "71    12\n",
      "67    12\n",
      "      ..\n",
      "37    10\n",
      "48     8\n",
      "50     6\n",
      "39     4\n",
      "43     2\n",
      "Name: department, Length: 80, dtype: int64\n",
      "1     0.012917\n",
      "55    0.012917\n",
      "72    0.012917\n",
      "71    0.012917\n",
      "67    0.012917\n",
      "        ...   \n",
      "37    0.010764\n",
      "48    0.008611\n",
      "50    0.006459\n",
      "39    0.004306\n",
      "43    0.002153\n",
      "Name: department, Length: 80, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of stores of each type\n",
    "store_counts = store_types[\"type\"].value_counts()\n",
    "print(store_counts)\n",
    "\n",
    "# Get the proportion of stores of each type\n",
    "store_props = store_types[\"type\"].value_counts(normalize=True)\n",
    "print(store_props)\n",
    "\n",
    "# Count the number of each department number and sort\n",
    "dept_counts_sorted = store_depts[\"department\"].value_counts(sort=True)\n",
    "print(dept_counts_sorted)\n",
    "\n",
    "# Get the proportion of departments of each number and sort\n",
    "dept_props_sorted = store_depts[\"department\"].value_counts(sort=True, normalize=True)\n",
    "print(dept_props_sorted)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4e6843c6bfdccd6baae1fcf31897a6fa3c17788250a79ec974d4dc6dacd1c12"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
